/*
 *  Copyright 2012 Hippo.
 *
 *  Licensed under the Apache License, Version 2.0 (the "License");
 *  you may not use this file except in compliance with the License.
 *  You may obtain a copy of the License at
 *
 *       http://www.apache.org/licenses/LICENSE-2.0
 *
 *  Unless required by applicable law or agreed to in writing, software
 *  distributed under the License is distributed on an "AS IS" BASIS,
 *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *  See the License for the specific language governing permissions and
 *  limitations under the License.
 */
package org.hippoecm.repository.standardworkflow;

import org.hippoecm.repository.api.Document;
import org.hippoecm.repository.api.WorkflowException;
import org.hippoecm.repository.ext.InternalWorkflow;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import javax.jcr.Node;
import javax.jcr.RepositoryException;
import javax.jcr.Session;
import java.io.Serializable;
import java.rmi.RemoteException;
import java.util.Collections;
import java.util.Map;
import java.util.Random;

/**
 * {@link WorkflowEventLoggerWorkflow} implementation that logs events in a random hierarchy of folders.
 * Each cluster has its own dedicated folder to avoid collisions (would be very rare) and to allow listeners
 * for events on specific clusters only. The event log can contain 5 million log entries easily per cluster node.
 * This means that for very active CMSes in large organisations with 2000 actions per day per cluster node you
 * should start thinking about purging your logs after about 7 years. {@link EventLogCleanupModule} can do
 * that for you.
 */
public class WorkflowEventLoggerWorkflowImpl implements WorkflowEventLoggerWorkflow, InternalWorkflow {

    private static final Logger log = LoggerFactory.getLogger(WorkflowEventLoggerWorkflowImpl.class);
    private static final Random random = new Random();
    
    private static final String ALPHABET = "0123456789abcdefghijklmnopqrstuvwxyz";
    private static final String DEFAULT_CLUSTER_NODE_ID = "default";
    private static final int HIERARCHY_DEPTH = 4;

    private final Session session;
    private final Node logFolder;

    public WorkflowEventLoggerWorkflowImpl(Session userSession, Session rootSession, Node subject) throws RepositoryException, WorkflowException {
        session = rootSession;
        Node rootLogFolder = null;
        if (subject != null) {
            rootLogFolder = session.getNodeByIdentifier(subject.getIdentifier());
        } else if (session.nodeExists("/hippo:log")) {
            rootLogFolder = session.getNode("/hippo:log");
        } else {
            throw new WorkflowException("No log to write to");
        }
        if (!rootLogFolder.isNodeType("hippolog:folder")) {
            throw new WorkflowException("Root log folder is not of the expected type");
        }
        String clusterId = getClusterNodeId();
        if (rootLogFolder.hasNode(clusterId)) {
            logFolder = rootLogFolder.getNode(clusterId);
        } else {
            logFolder = rootLogFolder.addNode(clusterId, "hippolog:folder");
        }
        session.save();
    }
    
    @Override
    public Map<String, Serializable> hints() throws WorkflowException, RemoteException, RepositoryException {
        return Collections.emptyMap();
    }

    @Override
    public void logEvent(final String who, final String className, final String methodName) throws RemoteException {
        logWorkflowStep(who, className, methodName, null, null, null);
    }

    @Override
    public void logWorkflowStep(String userName, String className, String methodName, Object[] args, Object returnObject, String documentPath) {
        try {
            char[] randomChars = generateRandomCharArray(HIERARCHY_DEPTH);
            Node folder = getOrCreateFolder(randomChars, HIERARCHY_DEPTH-1);

            long timestamp = System.currentTimeMillis();
            Node logNode = folder.addNode(String.valueOf(randomChars[HIERARCHY_DEPTH-1]), "hippolog:item");
            logNode.setProperty("hippolog:timestamp", timestamp);
            logNode.setProperty("hippolog:eventUser", userName == null ? "null" : userName);
            logNode.setProperty("hippolog:eventClass", className == null ? "null" : className);
            logNode.setProperty("hippolog:eventMethod", methodName == null ? "null" : methodName);
            if (className != null && className.equals(WorkflowEventLoggerWorkflowImpl.class.getName())) {
                if (log.isDebugEnabled()) {
                    log.debug("We don't log the event generated by our own invocation");
                }
                return;
            }
            // conditional properties
            if (documentPath != null) {
                logNode.setProperty("hippolog:eventDocument", documentPath);
            }
            String returnType = getReturnType(returnObject);
            if (returnType != null) {
                logNode.setProperty("hippolog:eventReturnType", returnType);
            }
            String returnValue = getReturnValue(returnObject);
            if (returnValue != null) {
                logNode.setProperty("hippolog:eventReturnValue", returnValue);
            }
            String[] arguments = replaceObjectsWithStrings(args);
            if (arguments != null) {
                logNode.setProperty("hippolog:eventArguments", arguments);
            }
            session.save();
        } catch (RepositoryException e) {
            log.warn("Event logging failed: " + e.getMessage(), e);
        }

    }

    private Node getOrCreateFolder(char[] chars, int len) throws RepositoryException {
        String itemRelPath = charArrayToRelPath(chars, len);
        if (!logFolder.hasNode(itemRelPath)) {
            if (len > 1) {
                getOrCreateFolder(chars, len-1);
            }
            return logFolder.addNode(itemRelPath, "hippolog:folder");
        }
        return logFolder.getNode(itemRelPath);

    }

    private String getReturnValue(Object returnObject) {
        if (returnObject == null) {
            return null;
        }
        if (returnObject instanceof Document) {
            Document document = (Document) returnObject;
            StringBuilder sb = new StringBuilder();
            sb.append("document[uuid=");
            sb.append(document.getIdentity());
            if (document.getIdentity() != null) {
                sb.append(",path='");
                try {
                    sb.append(session.getNodeByIdentifier(document.getIdentity()).getPath());
                } catch (RepositoryException e) {
                    sb.append("error:").append(e.getMessage());
                }
            }
            sb.append("']");
            return sb.toString();
        } else {
            return returnObject.toString();
        }
    }

    private static String getReturnType(Object returnObject) {
        if (returnObject == null) {
            return null;
        }
        if (returnObject instanceof Document) {
            return "document";
        } else {
            return returnObject.getClass().getName();
        }
    }

    private static String[] replaceObjectsWithStrings(Object[] args) {
        if (args == null) {
            return null;
        }
        String[] arguments = new String[args.length];
        for (int i = 0; i < args.length; i++) {
            if (args[i] != null) {
                arguments[i] = args[i].toString();
            } else {
                arguments[i] = "<null>";
            }
        }
        return arguments;
    }

    private static String charArrayToRelPath(char[] chars, int len) {
        StringBuilder sb = new StringBuilder((2*len)-1);
        for (int i = 0; i < len - 1; i++) {
            sb.append(chars[i]).append('/');
        }
        sb.append(chars[len-1]);
        return sb.toString();

    }

    private static char[] generateRandomCharArray(int len) {
        char[] result = new char[len];
        for (int i = 0; i < len; i++) {
            result[i] = ALPHABET.charAt(random.nextInt(ALPHABET.length()));
        }
        return result;
    }

    private static String getClusterNodeId() {
        return System.getProperty("org.apache.jackrabbit.core.cluster.node_id", DEFAULT_CLUSTER_NODE_ID);
    }
}
